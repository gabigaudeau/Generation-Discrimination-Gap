import re
from datasets import load_dataset
import random
from torch.utils.data import Dataset
import torch
import os
import openai


class RiddleSenseDataset(Dataset):
    DISCRIMINATION_PROMPT = "[QUESTION] Is \"[ANSWER]\" a correct answer to the riddle? Begin your answer with " \
                            "\"yes\" or \"no\" [OUTPUT]"
    GENERATION_PROMPT = "[QUESTION] The answer to the riddle is: [ANSWER]"

    def __init__(self, data, max_len, is_generation, is_exact_match):
        self.data = []
        for entry in data:
            question = entry['question']
            for i in range(len(entry['choices']['text'])):
                label = entry['choices']['label'][i]
                answer = entry['choices']['text'][i]
                if not is_generation and not is_exact_match:
                    self.data.append(DataEntry(question, answer, label == entry['answerKey'], 'yes'))
                    self.data.append(DataEntry(question, answer, label == entry['answerKey'], 'no'))
                else:
                    self.data.append(DataEntry(question, answer, label == entry['answerKey']))

        self.max_len = max_len
        self.is_generation = is_generation
        self.is_exact_match = is_exact_match

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        entry = self.data[index]

        if self.is_generation:
            prompt = self.GENERATION_PROMPT
            if self.is_exact_match:
                prompt = prompt.replace('[ANSWER]', "")
            else:
                prompt = prompt.replace('[ANSWER]', entry.answer)
        else:
            prompt = self.DISCRIMINATION_PROMPT
            prompt = prompt.replace('[ANSWER]', entry.answer)

        prompt = prompt.replace('[QUESTION]', entry.question)

        # Will only do so when an output is provided.
        self.prompt = prompt.replace('[OUTPUT]', entry.output)

        if entry.output == "":
            return self.prompt, entry.answer, entry.is_correct
        else:
            return self.prompt, entry.output, entry.is_correct


class DataEntry:
    """
    Input entry in the format, for e.g.,
    'answerKey': 'E',
    'question': 'A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand
    backwards and forwards across a field the size of a football pitch. What is the one thing he can put in it to
    make it lighter?',
    'choices':
            'label': ['A', 'B', 'C', 'D', 'E'],
            'text': ['throw', 'bit', 'gallon', 'mouse', 'hole']
    """

    def __init__(self, question, answer, is_correct, output=""):
        self.question = question.strip()
        self.answer = answer.strip()
        self.is_correct = is_correct
        self.output = output


def write_to_file(is_generation, is_exact_match, result):
    if is_generation:
        task = "generation"
    else:
        task = "discrimination"

    if is_exact_match:
        accuracy = "em"
    else:
        accuracy = "lp"

    # Write results
    file = open(f"{os.path.dirname(os.path.abspath(__file__))}/results/{MODEL}_{task}_{accuracy}_K{K}.txt",
                "w")
    file.write(f"{accuracy} for {task} model {MODEL}")
    file.write("\n----------------------\n")
    file.write(f"{result}  | ")
    file.write("\n----------------------\n\n")

    file.close()


def get_first_new_token(output):
        """Return the first nonempty token generated by the model (different from the prompt)."""
        split_output = output.split()

        index = 0
        while index < len(split_output):
            token = split_output[index]
            if token != "" and token is not None and token != " " and token.lower() != "a" and token.lower() != 'the' \
                    and token.lower() != "an":
                return token, index
            index += 1

        return None, None


def get_exact_match_for_generation(sample, model):
    sample_set = RiddleSenseDataset(sample, MAX_SEQUENCE_LENGTH,
                                    is_generation=True, is_exact_match=True)

    dataset = []
    for i in range(0, len(sample_set), 5):
        prompt, answer, label = sample_set[i]

        count = 1
        while not label:
            _, answer, label = sample_set[i + count]
            count += 1
        dataset.append((prompt, answer))

    total_score = 0
    processed = 0
    for entry in dataset:
        processed += 1
        if processed % 50 == 0:
            print(f'Processed {processed}/{len(dataset)}.')
        # Generate a response
        completion = openai.Completion.create(
            engine=model,
            prompt=entry[0],
            max_tokens=MAX_SEQUENCE_LENGTH + 10,
            n=K,
            temperature=0.5,
            stop=None,
        )

        number_of_matches = 0
        for choice in completion.choices:
            output = choice.text
            token, token_index = get_first_new_token(output)

            if token is not None:
                token = re.sub(r'[^\w\s]', '', token)
                answer_split = entry[1].split(" ")

                idx = 0
                while idx < len(answer_split):
                    if token.lower() == answer_split[idx]:
                        idx += 1
                        token_index += 1
                        if token_index < len(output):
                            token = output[token_index]
                            token = re.sub(r'[^\w\s]', '', token)
                        else:
                            break
                    else:
                        break

                if idx == len(answer_split):
                    number_of_matches += 1

        total_score += number_of_matches / len(completion.choices)

    result = total_score / len(dataset)
    print(f"Exact match accuracy for generation: {result}")
    return result


def get_exact_match_for_discrimination(sample, model):
    sample_set = RiddleSenseDataset(sample, MAX_SEQUENCE_LENGTH,
                                    is_generation=False, is_exact_match=True)

    total_score = 0
    processed = 0
    for prompt, answer, label in sample_set:
        processed += 1
        if processed % 50 == 0:
            print(f'Processed {processed}/{len(sample_set)}.')

        # Generate a response
        completion = openai.Completion.create(
            engine=model,
            prompt=prompt,
            max_tokens=MAX_SEQUENCE_LENGTH + 10,
            n=K,
            temperature=0.5,
            stop=None,
        )

        number_of_matches = 0
        for choice in completion.choices:
            output = choice.text
            token, token_index = get_first_new_token(output)

            if token is not None:
                token = re.sub(r'[^\w\s]', '', token)
                if (token.lower() == 'yes' and label) or \
                        (token.lower() == 'no' and not label):
                    number_of_matches += 1

        total_score += number_of_matches / len(completion.choices)

    result = total_score / len(sample_set)
    print(f"Exact match accuracy for discrimination: {result}")
    return result


if __name__ == '__main__':
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    print(f"Using: {device}\n")

    RANDOM_SEED = 42
    DO_SAMPLE = True
    MAX_SEQUENCE_LENGTH = 160
    K = 2
    BATCH_SIZE = 10

    # Setting the random seed.
    random.seed(RANDOM_SEED)
    torch.manual_seed(RANDOM_SEED)

    # print("\n---- FETCHING MODEL ----")
    # Define OpenAI API key
    openai.api_key = "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"
    #
    # Set up the model and prompt
    MODEL = "babbage"

    print("\n---- PREPARING DATASET ----")
    original_dataset = load_dataset('riddle_sense')
    sample = original_dataset["validation"]
    # sample = islice(original_dataset["validation"], 1)

    result = get_exact_match_for_generation(sample, MODEL)
    write_to_file(True, True, result)

    result = get_exact_match_for_discrimination(sample, MODEL)
    write_to_file(False, True, result)

